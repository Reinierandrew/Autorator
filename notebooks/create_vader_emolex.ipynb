{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import string\n",
    "import csv\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from collections import Counter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# set up emolex analysis\n",
    "emolex_df = pd.read_csv('../data/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt', sep='\\t', names=['word', 'emotion','association'])\n",
    "emolex_df = emolex_df[emolex_df.association == 1]\n",
    "emolex_words = emolex_df.pivot(index='word', columns='emotion', values='association')\n",
    "emolex_words = emolex_words.reset_index()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def count_emotions(text):\n",
    "\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "    words = text.split()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    emotions_count = emolex_words[emolex_words.word.isin(words)].sum()\n",
    "    emotions_count['word_count'] = len(words)\n",
    "\n",
    "    return emotions_count"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# read the restaurant dataset with vader scores\n",
    "df = pd.read_csv('../output/large_output/filtered_full.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# run the emolex analysis on the dataframe and add to the dataframe\n",
    "emotions_count = df['text'].apply(count_emotions)\n",
    "emolex = pd.concat([df, emotions_count], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "emolex.rename(columns={'Unnamed: 0': 'Record'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# set index to review id and drop columns not required\n",
    "emolex = emolex.reset_index()\n",
    "emolex = emolex.set_index('Record')\n",
    "emolex.drop(['index'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "emolex.to_csv('../output/large_output/emolex.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "output_rows = []\n",
    "with open('../output/large_output/emolex.csv', 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "\n",
    "    for row in reader:\n",
    "        stars = row['stars']\n",
    "        review_id = row['Record']\n",
    "        text = row['text']\n",
    "        sentiment_scores = sid.polarity_scores(text)\n",
    "        compound_score = sentiment_scores['compound']\n",
    "        positive_score = sentiment_scores['pos']\n",
    "        neutral_score = sentiment_scores['neu']\n",
    "        negative_score = sentiment_scores['neg']\n",
    "        output_row = {'review_id':review_id,'text':text, 'stars':stars, 'compound_sentiment': compound_score, 'positive': positive_score,'neutral': neutral_score, 'negative': negative_score}\n",
    "        output_rows.append(output_row)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "vader = pd.DataFrame(output_rows)\n",
    "vader.to_csv('../output/large_output/vader.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "vader.drop(['text','stars'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# merge vader and emolex\n",
    "vader['review_id'] = vader['review_id'].astype('int64')\n",
    "vader_emolex = pd.merge(vader, emolex, left_on='review_id',right_on='Unnamed: 0.1')\n",
    "vader_emolex.drop(['Unnamed: 0.1'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "vader_emolex.drop(['word','business_id'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "vader_emolex.to_csv('../output/large_output/vader_emolex.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# save to an excel file\n",
    "vader_emolex.to_excel('../output/large_output/vader_emolex.xlsx')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# remove stop words from text\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def remove_stopwords_punctuation(text):\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    text = ' '.join(filtered_tokens)\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "vader_emolex['text'] = df['text'].apply(remove_stopwords_punctuation)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "vader_emolex.to_excel('../output/large_output/vader_emolex.xlsx')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "counts = vader_emolex['stars'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    39004\n",
      "4    28477\n",
      "1    14235\n",
      "3    12676\n",
      "2    10900\n",
      "Name: stars, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(counts)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "grouped = vader_emolex.groupby('stars')['text'].apply(' '.join)\n",
    "results = []\n",
    "for group in grouped:\n",
    "    words = group.split()\n",
    "    counter = Counter(words)\n",
    "    top_words = dict(counter.most_common(30))\n",
    "    results.append(top_words)\n",
    "\n",
    "#create a DataFrame from the results\n",
    "df_results = pd.DataFrame(results)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "df_results.head(50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['food', 'us', 'place', 'restaurant', 'chicken', 'im', 'sauce', 'ive', 'one'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[38], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mdf_results\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfood\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mus\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mplace\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrestaurant\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mchicken\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mim\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msauce\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mive\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mone\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/python31/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[1;32m    326\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    327\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39m_format_argument_list(allow_args)),\n\u001B[1;32m    328\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[1;32m    329\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mfind_stack_level(),\n\u001B[1;32m    330\u001B[0m     )\n\u001B[0;32m--> 331\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/python31/lib/python3.10/site-packages/pandas/core/frame.py:5399\u001B[0m, in \u001B[0;36mDataFrame.drop\u001B[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[1;32m   5251\u001B[0m \u001B[38;5;129m@deprecate_nonkeyword_arguments\u001B[39m(version\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, allowed_args\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mself\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m   5252\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdrop\u001B[39m(  \u001B[38;5;66;03m# type: ignore[override]\u001B[39;00m\n\u001B[1;32m   5253\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   5260\u001B[0m     errors: IgnoreRaise \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   5261\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   5262\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   5263\u001B[0m \u001B[38;5;124;03m    Drop specified labels from rows or columns.\u001B[39;00m\n\u001B[1;32m   5264\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   5397\u001B[0m \u001B[38;5;124;03m            weight  1.0     0.8\u001B[39;00m\n\u001B[1;32m   5398\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 5399\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   5400\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5401\u001B[0m \u001B[43m        \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5402\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5403\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5404\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5405\u001B[0m \u001B[43m        \u001B[49m\u001B[43minplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minplace\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5406\u001B[0m \u001B[43m        \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5407\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/python31/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[1;32m    326\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    327\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39m_format_argument_list(allow_args)),\n\u001B[1;32m    328\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[1;32m    329\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mfind_stack_level(),\n\u001B[1;32m    330\u001B[0m     )\n\u001B[0;32m--> 331\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/python31/lib/python3.10/site-packages/pandas/core/generic.py:4505\u001B[0m, in \u001B[0;36mNDFrame.drop\u001B[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[1;32m   4503\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m axis, labels \u001B[38;5;129;01min\u001B[39;00m axes\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m   4504\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m labels \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 4505\u001B[0m         obj \u001B[38;5;241m=\u001B[39m \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_drop_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4507\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m inplace:\n\u001B[1;32m   4508\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_inplace(obj)\n",
      "File \u001B[0;32m~/miniconda3/envs/python31/lib/python3.10/site-packages/pandas/core/generic.py:4546\u001B[0m, in \u001B[0;36mNDFrame._drop_axis\u001B[0;34m(self, labels, axis, level, errors, only_slice)\u001B[0m\n\u001B[1;32m   4544\u001B[0m         new_axis \u001B[38;5;241m=\u001B[39m axis\u001B[38;5;241m.\u001B[39mdrop(labels, level\u001B[38;5;241m=\u001B[39mlevel, errors\u001B[38;5;241m=\u001B[39merrors)\n\u001B[1;32m   4545\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 4546\u001B[0m         new_axis \u001B[38;5;241m=\u001B[39m \u001B[43maxis\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4547\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m axis\u001B[38;5;241m.\u001B[39mget_indexer(new_axis)\n\u001B[1;32m   4549\u001B[0m \u001B[38;5;66;03m# Case for non-unique axis\u001B[39;00m\n\u001B[1;32m   4550\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniconda3/envs/python31/lib/python3.10/site-packages/pandas/core/indexes/base.py:6934\u001B[0m, in \u001B[0;36mIndex.drop\u001B[0;34m(self, labels, errors)\u001B[0m\n\u001B[1;32m   6932\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mask\u001B[38;5;241m.\u001B[39many():\n\u001B[1;32m   6933\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m errors \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m-> 6934\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlist\u001B[39m(labels[mask])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not found in axis\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   6935\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m indexer[\u001B[38;5;241m~\u001B[39mmask]\n\u001B[1;32m   6936\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdelete(indexer)\n",
      "\u001B[0;31mKeyError\u001B[0m: \"['food', 'us', 'place', 'restaurant', 'chicken', 'im', 'sauce', 'ive', 'one'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df_results.drop(['food','place','restaurant','chicken','im','sauce','ive','one'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "    like   back  service  order  would   time  ordered   good    get   never  \\\n0   7636   6835     6835   6833   6740   6470     6296   6125   6007  5688.0   \n1   7664   4758     5616   4336   5259   5073     5227   8544   4871     NaN   \n2   8710   4740     6189   4569   6562   5284     5377  13893   5637     NaN   \n3  15675   9916    11179   9193  10664  11393    10200  28563  11540     NaN   \n4  16181  12492    14063   9818   9648  13656    10961  23872  13314     NaN   \n\n   ...  delicious     well      try  definitely    rice     best    fresh  \\\n0  ...        NaN      NaN      NaN         NaN     NaN      NaN      NaN   \n1  ...        NaN      NaN      NaN         NaN     NaN      NaN      NaN   \n2  ...        NaN      NaN      NaN         NaN     NaN      NaN      NaN   \n3  ...     9503.0   8786.0   8312.0      7516.0  7288.0      NaN      NaN   \n4  ...    15636.0  10528.0  10481.0         NaN     NaN  13941.0  10594.0   \n\n      love  amazing  always  \n0      NaN      NaN     NaN  \n1      NaN      NaN     NaN  \n2      NaN      NaN     NaN  \n3      NaN      NaN     NaN  \n4  10090.0   9605.0  9409.0  \n\n[5 rows x 42 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>like</th>\n      <th>back</th>\n      <th>service</th>\n      <th>order</th>\n      <th>would</th>\n      <th>time</th>\n      <th>ordered</th>\n      <th>good</th>\n      <th>get</th>\n      <th>never</th>\n      <th>...</th>\n      <th>delicious</th>\n      <th>well</th>\n      <th>try</th>\n      <th>definitely</th>\n      <th>rice</th>\n      <th>best</th>\n      <th>fresh</th>\n      <th>love</th>\n      <th>amazing</th>\n      <th>always</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7636</td>\n      <td>6835</td>\n      <td>6835</td>\n      <td>6833</td>\n      <td>6740</td>\n      <td>6470</td>\n      <td>6296</td>\n      <td>6125</td>\n      <td>6007</td>\n      <td>5688.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7664</td>\n      <td>4758</td>\n      <td>5616</td>\n      <td>4336</td>\n      <td>5259</td>\n      <td>5073</td>\n      <td>5227</td>\n      <td>8544</td>\n      <td>4871</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8710</td>\n      <td>4740</td>\n      <td>6189</td>\n      <td>4569</td>\n      <td>6562</td>\n      <td>5284</td>\n      <td>5377</td>\n      <td>13893</td>\n      <td>5637</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>15675</td>\n      <td>9916</td>\n      <td>11179</td>\n      <td>9193</td>\n      <td>10664</td>\n      <td>11393</td>\n      <td>10200</td>\n      <td>28563</td>\n      <td>11540</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>9503.0</td>\n      <td>8786.0</td>\n      <td>8312.0</td>\n      <td>7516.0</td>\n      <td>7288.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>16181</td>\n      <td>12492</td>\n      <td>14063</td>\n      <td>9818</td>\n      <td>9648</td>\n      <td>13656</td>\n      <td>10961</td>\n      <td>23872</td>\n      <td>13314</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>15636.0</td>\n      <td>10528.0</td>\n      <td>10481.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13941.0</td>\n      <td>10594.0</td>\n      <td>10090.0</td>\n      <td>9605.0</td>\n      <td>9409.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 42 columns</p>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.head(50)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# create a list of words from your dataframe column\n",
    "words = vader_emolex['text'].str.split(expand=True).stack().tolist()\n",
    "\n",
    "# count the most common words\n",
    "word_counts = Counter(words).most_common()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "word_df = pd.DataFrame(word_counts, columns=['word', 'count'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "word_top50 = word_df.sort_values(by='count', ascending=False)[:50]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "drop_words=['food','place','one','two','restaurant','menu','ive','im','lunch','table']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "filtered_words = word_top50[word_top50.word.isin(drop_words) == False]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
